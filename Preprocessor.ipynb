{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/constantin/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.21.3 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/constantin/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.21.3 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/constantin/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.svm.classes module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.svm. Anything that cannot be imported from sklearn.svm is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/constantin/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.21.3 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import classifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "test_file = \"./evaluation_examples.csv\"\n",
    "test_data = classifier.load_data(test_file)\n",
    "test_text = test_data[0]\n",
    "\n",
    "#as labels we use the predictions of the classifier\n",
    "polarity_prediction = classifier.classify(test_text, './polarity_classifier.sav')\n",
    "domain_prediction = classifier.classify(test_text, './domain_classifier.sav')\n",
    "\n",
    "test_text_0_3 = []\n",
    "test_text_1_3 = []\n",
    "test_text_0_4 = []\n",
    "test_text_1_4 = []\n",
    "\n",
    "#split the reviews according to their predictions\n",
    "for idx in range(len(polarity_prediction)):\n",
    "    if domain_prediction[idx] == 0 and polarity_prediction[idx] == 3:\n",
    "        test_text_0_3.append(test_text[idx])\n",
    "    elif domain_prediction[idx] == 1 and polarity_prediction[idx] == 3:\n",
    "        test_text_1_3.append(test_text[idx])\n",
    "    elif domain_prediction[idx] == 0 and polarity_prediction[idx] == 4:\n",
    "        test_text_0_4.append(test_text[idx])\n",
    "    else:\n",
    "        test_text_1_4.append(test_text[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a tf-idf list for each set of reviews\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "def create_tf_idf_list(documents):\n",
    "    tf_idf_matrix = vectorizer.fit_transform(documents)\n",
    "    #use the sum of tf-idf values across all documents as the overall score for each ngram\n",
    "    scores = zip(vectorizer.get_feature_names(),\n",
    "                     np.asarray(tf_idf_matrix.sum(axis=0)).ravel())\n",
    "    \n",
    "    #sort the list of ngrams by the previously calculated score\n",
    "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_scores\n",
    "\n",
    "sorted_scores_0_3 = create_tf_idf_list(test_text_0_3)\n",
    "sorted_scores_1_3 = create_tf_idf_list(test_text_1_3)\n",
    "sorted_scores_0_4 = create_tf_idf_list(test_text_0_4)\n",
    "sorted_scores_1_4 = create_tf_idf_list(test_text_1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the tf-idf scores to compute a measure on polarity for each ngram and filter them out of the lists accordingly\n",
    "def filter_polarity(pos_list, neg_list):\n",
    "    for word in neg_list[:]:\n",
    "        #check if word is contained in pos_list\n",
    "        tmp = [item for item in pos_list if item[0] == word[0]]\n",
    "        if len(tmp) == 1:\n",
    "            q = tmp[0][1]/word[1]\n",
    "\n",
    "            if q < .2: #the ngram has negative polarity\n",
    "                pos_list.remove(tmp[0])\n",
    "            elif q > 5: #the ngram has positive polarity\n",
    "                neg_list.remove(word)\n",
    "            else: #the ngram is neutral\n",
    "                pos_list.remove(tmp[0])\n",
    "                neg_list.remove(word)\n",
    "\n",
    "filter_polarity(sorted_scores_0_3, sorted_scores_0_4)\n",
    "filter_polarity(sorted_scores_1_3, sorted_scores_1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove tf-idf scores for all ngrams\n",
    "sorted_scores_0_3 = [i[0] for i in sorted_scores_0_3]\n",
    "sorted_scores_1_3 = [i[0] for i in sorted_scores_1_3]\n",
    "sorted_scores_0_4 = [i[0] for i in sorted_scores_0_4]\n",
    "sorted_scores_1_4 = [i[0] for i in sorted_scores_1_4]\n",
    "\n",
    "#map all negative/positive ngrams of one domain to the most dominant token of opposite polarity in the same domain\n",
    "replacement_dict_domain0 = {i: sorted_scores_0_4[0] for i in sorted_scores_0_3}\n",
    "replacement_dict_domain0_tmp = {i: sorted_scores_0_3[0] for i in sorted_scores_0_4}\n",
    "replacement_dict_domain1 = {i: sorted_scores_1_4[0] for i in sorted_scores_1_3}\n",
    "replacement_dict_domain1_tmp = {i: sorted_scores_1_3[0] for i in sorted_scores_1_4}\n",
    "\n",
    "#this mapping can be viewed as our learned model\n",
    "replacement_dict_domain0.update(replacement_dict_domain0_tmp)\n",
    "replacement_dict_domain1.update(replacement_dict_domain1_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/constantin/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.21.3 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/constantin/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.21.3 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/constantin/.local/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.21.3 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#get the data to be manipulated\n",
    "test_file = \"./evaluation_examples.csv\"\n",
    "test_data = classifier.load_data(test_file)\n",
    "test_text = test_data[0]\n",
    "\n",
    "#use this prediction to apply the correct dictionary to each review\n",
    "domain_prediction = classifier.classify(test_text, './domain_classifier.sav')\n",
    "\n",
    "electronics_indices = list(filter(lambda i: domain_prediction[i] == 0, range(len(domain_prediction))))\n",
    "kitchen_indices = list(filter(lambda i: domain_prediction[i] == 1, range(len(domain_prediction))))\n",
    "\n",
    "#get the same preprocessor as the one we used to learn the model\n",
    "preprocessor = vectorizer.build_preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the ngrams by length so that longer ngrams get replaced first\n",
    "rep_sorted_domain0 = sorted(replacement_dict_domain0, key=len, reverse=True)\n",
    "pattern_domain0 = re.compile('|'.join(r'\\b%s\\b' % re.escape(s) for s in rep_sorted_domain0))\n",
    "\n",
    "#apply the mapping defined by the dictionary to each review\n",
    "for idx in electronics_indices:\n",
    "    s = test_data.at[idx, 0]\n",
    "    s = preprocessor(s)\n",
    "    s = pattern_domain0.sub(lambda match: replacement_dict_domain0[match.group(0)], s)\n",
    "    test_data.at[idx, 0] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_sorted_domain1 = sorted(replacement_dict_domain1, key=len, reverse=True)\n",
    "pattern_domain1 = re.compile('|'.join(r'\\b%s\\b' % re.escape(s) for s in rep_sorted_domain1))\n",
    "    \n",
    "for idx in kitchen_indices:\n",
    "    s = test_data.at[idx, 0]\n",
    "    s = preprocessor(s)\n",
    "    s = pattern_domain1.sub(lambda match: replacement_dict_domain1[match.group(0)], s)\n",
    "    test_data.at[idx, 0] = s\n",
    "\n",
    "#write the processed data to a new csv file\n",
    "test_data.to_csv('processed_evaluation_examples.csv', index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
